{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Decision Tree Model (ID3 Algorithm)**"
      ],
      "metadata": {
        "id": "tEDGAQKvM0KQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "0Z1tK7fwM_0P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {
        "id": "lkHCcSL7McvR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import os\n",
        "os.environ[\"PATH\"] += os.pathsep + r\"C:\\Program Files\\Graphviz\\bin\"\n",
        "from graphviz import Digraph"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Loading & Basic cleaning"
      ],
      "metadata": {
        "id": "NH8Ko_Y_NEvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"DatasetofDiabetes.csv\")\n",
        "\n",
        "# Drop duplicates\n",
        "df = df.drop_duplicates()\n",
        "print(f\"Rows after dropping duplicates: {df.shape[0]}\")\n",
        "\n",
        "# Numeric features (NOT ID or No_Pation)\n",
        "numeric_cols = ['AGE', 'Urea', 'Cr', 'HbA1c', 'Chol',\n",
        "                'TG', 'HDL', 'LDL', 'VLDL', 'BMI']\n",
        "feature_cols = numeric_cols + ['Gender']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q20qFQP_NOuL",
        "outputId": "f49d1e05-68d2-4334-9c73-2df62c579b83"
      },
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows after dropping duplicates: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Outlier Handling (IQR + median)"
      ],
      "metadata": {
        "id": "QXvFa5aTNjna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in numeric_cols:\n",
        "    Q1, Q3 = df[col].quantile(0.25), df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower, upper = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR\n",
        "    median_val = df[col].median()\n",
        "    mask = (df[col] < lower) | (df[col] > upper)\n",
        "    outlier_count = mask.sum()\n",
        "    df.loc[mask, col] = median_val\n",
        "    print(f\"{col}: {outlier_count} outliers replaced with median {median_val:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaTPCBnuOLs2",
        "outputId": "10332ad8-6c4d-477e-c27e-8356e836001a"
      },
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AGE: 98 outliers replaced with median 55.000\n",
            "Urea: 65 outliers replaced with median 4.600\n",
            "Cr: 52 outliers replaced with median 60.000\n",
            "HbA1c: 6 outliers replaced with median 8.000\n",
            "Chol: 27 outliers replaced with median 4.800\n",
            "TG: 55 outliers replaced with median 2.000\n",
            "HDL: 50 outliers replaced with median 1.100\n",
            "LDL: 11 outliers replaced with median 2.500\n",
            "VLDL: 74 outliers replaced with median 0.900\n",
            "BMI: 3 outliers replaced with median 30.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Target (Class) Preprocessing:  N,P,Y  →  0,1,2"
      ],
      "metadata": {
        "id": "lC5m3wFWOQzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['CLASS'] = df['CLASS'].astype(str).str.strip().str.upper()\n",
        "label_map = {'N': 0, 'P': 1, 'Y': 2}\n",
        "y = df['CLASS'].map(label_map)\n",
        "y = y.astype(int)\n",
        "\n",
        "print(\"Class counts:\")\n",
        "print(y.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47BMSxn8OZoi",
        "outputId": "9c48959c-389e-4566-e179-17f70086fa55"
      },
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class counts:\n",
            "CLASS\n",
            "2    844\n",
            "0    103\n",
            "1     53\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Gender Preprocessing: M,F  →  1,0"
      ],
      "metadata": {
        "id": "NGs3gLr6OcIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Gender'] = df['Gender'].astype(str).str.strip().str.upper()\n",
        "df['Gender'] = df['Gender'].map({'M': 1, 'F': 0})\n",
        "\n",
        "print(df['Gender'].value_counts(dropna=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBT-wTmkOgmh",
        "outputId": "26ef31fe-e9c7-4980-f2e2-9ebb2a71ca6f"
      },
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gender\n",
            "1    565\n",
            "0    435\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4 (continued): Build Feature Matrices"
      ],
      "metadata": {
        "id": "4vTznRyjOpdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_numeric = df[numeric_cols].copy()\n",
        "gender_col = df['Gender'].copy()\n",
        "\n",
        "print(f\"\\nFinal dataset size after cleaning: {len(df)} samples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0j95rSzOylK",
        "outputId": "8dc51c4f-3745-48aa-e8cd-9efffb30b7bc"
      },
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final dataset size after cleaning: 1000 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Feature Importance (Correlation with Class)"
      ],
      "metadata": {
        "id": "NUtZIBccO5Uz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_corr = df.copy()\n",
        "df_corr['CLASS_NUM'] = y  # numeric target\n",
        "\n",
        "corr = df_corr[numeric_cols + ['CLASS_NUM']].corr()\n",
        "feat_corr = corr['CLASS_NUM'].sort_values(ascending=False)\n",
        "print(feat_corr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vh3UMhY4O-Oq",
        "outputId": "98635f26-5520-420c-be6c-eeacf1a8978b"
      },
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLASS_NUM    1.000000\n",
            "BMI          0.576713\n",
            "HbA1c        0.535989\n",
            "AGE          0.409657\n",
            "TG           0.227809\n",
            "VLDL         0.199177\n",
            "Chol         0.172869\n",
            "Urea         0.075775\n",
            "Cr           0.020217\n",
            "HDL          0.013369\n",
            "LDL         -0.016643\n",
            "Name: CLASS_NUM, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Discretization of numeric features"
      ],
      "metadata": {
        "id": "Vi7UgtOQPBD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3 bins: 0 = Low, 1 = Med, 2 = High\n",
        "\n",
        "def discretize_dataframe(X_num, n_bins=3):                          # Function to discretize each numeric column into n_bins using quantiles, and returns dataframe with integer codes\n",
        "\n",
        "    X_disc = pd.DataFrame(index=X_num.index)                        #Makes a new empty DataFrame,Same number of rows as the original\n",
        "    for col in X_num.columns:\n",
        "        bins = pd.qcut(X_num[col], q=n_bins, duplicates='drop')     #Sorts the values in this column,Splits them into 3 equal-sized groups\n",
        "        codes, uniques = pd.factorize(bins, sort=True)              #Convert intervals to numbers\n",
        "        X_disc[col] = codes\n",
        "        print(f\"{col}: unique intervals -> {list(uniques)}\")\n",
        "    return X_disc\n",
        "\n",
        "X_disc_numeric = discretize_dataframe(X_numeric, n_bins=3)\n",
        "\n",
        "# Add gender as already discrete {0,1}\n",
        "X_final = X_disc_numeric.copy()\n",
        "X_final['Gender'] = gender_col.values\n",
        "\n",
        "print(\"\\nSample of discretized features:\")\n",
        "print(X_final.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xncAXP1TPGOy",
        "outputId": "c5ace43e-0a77-4c61-8e82-a8b4361ac258"
      },
      "execution_count": 284,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AGE: unique intervals -> [Interval(38.999, 54.0, closed='right'), Interval(54.0, 56.0, closed='right'), Interval(56.0, 71.0, closed='right')]\n",
            "Urea: unique intervals -> [Interval(1.0990000000000002, 4.0, closed='right'), Interval(4.0, 5.0, closed='right'), Interval(5.0, 8.7, closed='right')]\n",
            "Cr: unique intervals -> [Interval(19.999, 53.0, closed='right'), Interval(53.0, 66.0, closed='right'), Interval(66.0, 107.0, closed='right')]\n",
            "HbA1c: unique intervals -> [Interval(1.999, 7.0, closed='right'), Interval(7.0, 9.3, closed='right'), Interval(9.3, 15.0, closed='right')]\n",
            "Chol: unique intervals -> [Interval(1.999, 4.3, closed='right'), Interval(4.3, 5.2, closed='right'), Interval(5.2, 7.9, closed='right')]\n",
            "TG: unique intervals -> [Interval(0.299, 1.7, closed='right'), Interval(1.7, 2.2, closed='right'), Interval(2.2, 5.0, closed='right')]\n",
            "HDL: unique intervals -> [Interval(0.399, 1.0, closed='right'), Interval(1.0, 1.2, closed='right'), Interval(1.2, 1.9, closed='right')]\n",
            "LDL: unique intervals -> [Interval(0.299, 2.0, closed='right'), Interval(2.0, 3.0, closed='right'), Interval(3.0, 5.5, closed='right')]\n",
            "VLDL: unique intervals -> [Interval(0.099, 0.8, closed='right'), Interval(0.8, 1.1, closed='right'), Interval(1.1, 2.6, closed='right')]\n",
            "BMI: unique intervals -> [Interval(18.999, 27.33, closed='right'), Interval(27.33, 32.0, closed='right'), Interval(32.0, 43.25, closed='right')]\n",
            "\n",
            "Sample of discretized features:\n",
            "   AGE  Urea  Cr  HbA1c  Chol  TG  HDL  LDL  VLDL  BMI  Gender\n",
            "0    0     1   0      0     0   0    1    0     0    0       0\n",
            "1    1     1   1      0     0   0    1    1     0    0       1\n",
            "2    0     1   0      0     0   0    1    0     0    0       0\n",
            "3    0     1   0      0     0   0    1    0     0    0       0\n",
            "4    1     2   0      0     1   0    0    0     0    0       1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7: Train/Test split"
      ],
      "metadata": {
        "id": "ZW03gs9iP0dT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_final, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"\\nData sizes:\")\n",
        "print(\"Training:\", len(X_train))\n",
        "print(\"Testing :\", len(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBmriTUCPSR1",
        "outputId": "c2f7f291-5b5b-4b19-fcdc-bd0877a63392"
      },
      "execution_count": 285,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data sizes:\n",
            "Training: 800\n",
            "Testing : 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 8: ID3 IMPLEMENTATION FOR DISCRETE ATTRIBUTES**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "VwCyV0HgQWF0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8.1: Entropy + Information Gain implementations"
      ],
      "metadata": {
        "id": "tAWzy96KQhDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def entropy(y_vec):\n",
        "    values, counts = np.unique(y_vec, return_counts=True)\n",
        "    prob = counts / len(y_vec)\n",
        "    return -np.sum(prob * np.log2(prob + 1e-9))\n",
        "\n",
        "def information_gain_discrete(X_col, y_vec):\n",
        "    H_parent = entropy(y_vec)\n",
        "    values, counts = np.unique(X_col, return_counts=True)\n",
        "    weighted_entropy = 0.0\n",
        "\n",
        "    for v, cnt in zip(values, counts):\n",
        "        y_v = y_vec[X_col == v]\n",
        "        weighted_entropy += (cnt / len(X_col)) * entropy(y_v)\n",
        "\n",
        "    return H_parent - weighted_entropy\n"
      ],
      "metadata": {
        "id": "0yi9xX3XRiRy"
      },
      "execution_count": 286,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8.2: Attribute Selection"
      ],
      "metadata": {
        "id": "VFI-h0wKRnBG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def best_attribute(X, y_vec):\n",
        "    best_attr = None\n",
        "    best_gain = -1\n",
        "\n",
        "    for col in X.columns:\n",
        "        gain = information_gain_discrete(X[col], y_vec)\n",
        "        if gain > best_gain:\n",
        "            best_gain = gain\n",
        "            best_attr = col\n",
        "\n",
        "    return best_attr, best_gain\n"
      ],
      "metadata": {
        "id": "eZ_-m9QhRrbK"
      },
      "execution_count": 287,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8.3: Tree Node Class implementation"
      ],
      "metadata": {
        "id": "OALBX3jGRs6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "    def __init__(self, feature=None, children=None, value=None):\n",
        "        self.feature = feature\n",
        "        self.children = children if children is not None else {}\n",
        "        self.value = value\n"
      ],
      "metadata": {
        "id": "FFwdV4L8RyNf"
      },
      "execution_count": 288,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8.4: Majority Class Helper Function implementation"
      ],
      "metadata": {
        "id": "2OYUzWU7R0_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def majority_class(y_vec):\n",
        "    values, counts = np.unique(y_vec, return_counts=True)\n",
        "    return values[np.argmax(counts)]\n"
      ],
      "metadata": {
        "id": "Ca4HFRgWSJVu"
      },
      "execution_count": 289,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tree"
      ],
      "metadata": {
        "id": "JpQh7wWlY94x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLASS_LABELS = {\n",
        "    0: \"N (Non-diabetic)\",\n",
        "    1: \"P (Predict-diabetic)\",\n",
        "    2: \"Y (Diabetic)\",\n",
        "}\n",
        "\n",
        "def visualize_tree(node, filename=\"ID3_diabetes_tree\"):\n",
        "    \"\"\"\n",
        "    Visualize the custom ID3 decision tree using Graphviz and save as PNG.\n",
        "    \"\"\"\n",
        "    dot = Digraph()\n",
        "\n",
        "    def add_nodes_edges(node, parent_id=None, edge_label=\"\"):\n",
        "        # Unique ID to avoid duplicate node names\n",
        "        node_id = str(id(node))\n",
        "\n",
        "        # If node is a leaf\n",
        "        if node.value is not None:\n",
        "            label = CLASS_LABELS.get(node.value, str(node.value))\n",
        "            dot.node(node_id, label,\n",
        "                     shape=\"box\", style=\"filled\", color=\"lightgreen\")\n",
        "        else:\n",
        "            # Decision node\n",
        "            dot.node(node_id, f\"{node.feature}\",\n",
        "                     shape=\"ellipse\", style=\"filled\", color=\"lightblue\")\n",
        "\n",
        "        # If not root, connect to parent\n",
        "        if parent_id is not None:\n",
        "            dot.edge(parent_id, node_id, label=str(edge_label))\n",
        "\n",
        "        # Recursively add child nodes\n",
        "        if node.value is None:\n",
        "            for val, child in node.children.items():\n",
        "                add_nodes_edges(child, node_id, edge_label=val)\n",
        "\n",
        "    # Build graph starting from the root\n",
        "    add_nodes_edges(node)\n",
        "\n",
        "    # Export as PNG\n",
        "    dot.render(filename, format=\"png\", cleanup=True)\n",
        "    print(f\"\\nGraphical tree saved as: {filename}.png\")\n"
      ],
      "metadata": {
        "id": "ZTMyYhCIY_W5"
      },
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8.5: The ID3 Training Algorithm"
      ],
      "metadata": {
        "id": "4kitVh7ySLcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def id3(X, y_vec, depth=0, max_depth=None):\n",
        "\n",
        "    if len(np.unique(y_vec)) == 1:\n",
        "        return Node(value=y_vec.iloc[0])\n",
        "\n",
        "    if X.shape[1] == 0:\n",
        "        return Node(value=majority_class(y_vec))\n",
        "\n",
        "    if (max_depth is not None) and (depth >= max_depth):\n",
        "        return Node(value=majority_class(y_vec))\n",
        "\n",
        "    best_attr, best_gain = best_attribute(X, y_vec)\n",
        "\n",
        "    if best_gain <= 1e-6:\n",
        "        return Node(value=majority_class(y_vec))\n",
        "\n",
        "    node = Node(feature=best_attr, children={})\n",
        "    attr_values = X[best_attr].unique()\n",
        "\n",
        "    for v in attr_values:\n",
        "        mask = X[best_attr] == v\n",
        "        X_subset = X.loc[mask].drop(columns=[best_attr])\n",
        "        y_subset = y_vec.loc[mask]\n",
        "\n",
        "        if len(y_subset) == 0:\n",
        "            child = Node(value=majority_class(y_vec))\n",
        "        else:\n",
        "            child = id3(X_subset, y_subset, depth=depth + 1, max_depth=max_depth)\n",
        "\n",
        "        node.children[v] = child\n",
        "\n",
        "    return node\n"
      ],
      "metadata": {
        "id": "3VL8dLwDSPZC"
      },
      "execution_count": 291,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8.6: Prediction Logic"
      ],
      "metadata": {
        "id": "hE-zumMjSSQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_one(node, sample):\n",
        "    if node.value is not None:\n",
        "        return node.value\n",
        "\n",
        "    attr_value = sample[node.feature]\n",
        "    child = node.children.get(attr_value, None)\n",
        "\n",
        "    if child is None:\n",
        "        leaf_values = [c.value for c in node.children.values() if c.value is not None]\n",
        "        if len(leaf_values) > 0:\n",
        "            return max(set(leaf_values), key=leaf_values.count)\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    return predict_one(child, sample)\n",
        "\n",
        "def predict(tree, X):\n",
        "    return np.array([predict_one(tree, X.iloc[i]) for i in range(len(X))])\n"
      ],
      "metadata": {
        "id": "lVE2aiKXSas-"
      },
      "execution_count": 292,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 9: Building & Evaluating Tree"
      ],
      "metadata": {
        "id": "3uFTLKGlSeO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree = id3(X_train, y_train, max_depth=5)\n",
        "visualize_tree(tree, \"ID3_diabetes_tree\")\n",
        "\n",
        "y_train_pred = predict(tree, X_train)\n",
        "y_test_pred = predict(tree, X_test)\n",
        "\n",
        "train_acc = accuracy_score(y_train, y_train_pred)\n",
        "test_acc = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"MODEL EVALUATION (ID3 Decision Tree)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(f\"Training Accuracy: {train_acc:.4f}\")\n",
        "print(f\"Testing  Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "target_names = [\n",
        "    'Non-Diabetic (0)',\n",
        "    'Predict-Diabetic (1)',\n",
        "    'Diabetic (2)'\n",
        "]\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(\"-\" * 70)\n",
        "print(classification_report(\n",
        "    y_test,\n",
        "    y_test_pred,\n",
        "    target_names=target_names,\n",
        "    digits=3\n",
        "))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_test_pred)\n",
        "cm_df = pd.DataFrame(\n",
        "    cm,\n",
        "    index=[f\"Actual {name}\" for name in target_names],\n",
        "    columns=[f\"Pred {name}\" for name in target_names]\n",
        ")\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(\"-\" * 70)\n",
        "print(cm_df)\n",
        "print(\"-\" * 70)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBTFNe-fVF0u",
        "outputId": "afd4bcf2-2201-480a-c9a5-16bdb4cd2ea2"
      },
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Graphical tree saved as: ID3_diabetes_tree.png\n",
            "\n",
            "======================================================================\n",
            "MODEL EVALUATION (ID3 Decision Tree)\n",
            "======================================================================\n",
            "Training Accuracy: 0.9413\n",
            "Testing  Accuracy: 0.9250\n",
            "\n",
            "Classification Report:\n",
            "----------------------------------------------------------------------\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "    Non-Diabetic (0)      0.630     0.810     0.708        21\n",
            "Predict-Diabetic (1)      0.500     0.100     0.167        10\n",
            "        Diabetic (2)      0.977     0.988     0.982       169\n",
            "\n",
            "            accuracy                          0.925       200\n",
            "           macro avg      0.702     0.633     0.619       200\n",
            "        weighted avg      0.916     0.925     0.913       200\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "----------------------------------------------------------------------\n",
            "                             Pred Non-Diabetic (0)  Pred Predict-Diabetic (1)  \\\n",
            "Actual Non-Diabetic (0)                         17                          1   \n",
            "Actual Predict-Diabetic (1)                      8                          1   \n",
            "Actual Diabetic (2)                              2                          0   \n",
            "\n",
            "                             Pred Diabetic (2)  \n",
            "Actual Non-Diabetic (0)                      3  \n",
            "Actual Predict-Diabetic (1)                  1  \n",
            "Actual Diabetic (2)                        167  \n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5E_6DrKGcCRJ"
      },
      "execution_count": 293,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 10: Analysis for Gender & Age"
      ],
      "metadata": {
        "id": "45hbNb0fVXi-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# GENDER VS DIABETES (CLEAN FORMATTED OUTPUT)\n",
        "gender_class_pct = pd.crosstab(df['Gender'], df['CLASS'], normalize='index') * 100\n",
        "\n",
        "gender_class_pct_rounded = gender_class_pct.round(2)\n",
        "\n",
        "for g in gender_class_pct_rounded.index:\n",
        "    label = \"Female\" if g == 0 else \"Male\"\n",
        "    print(f\"\\n{label}:\")\n",
        "    for cls, val in gender_class_pct_rounded.loc[g].items():\n",
        "        print(f\"  Class {cls}: {val:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5euN00zhVa1O",
        "outputId": "28c201de-f391-40a0-bbb5-98efa304efff"
      },
      "execution_count": 294,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Female:\n",
            "  Class N: 14.71%\n",
            "  Class P: 3.91%\n",
            "  Class Y: 81.38%\n",
            "\n",
            "Male:\n",
            "  Class N: 6.90%\n",
            "  Class P: 6.37%\n",
            "  Class Y: 86.73%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUNG VS OLD\n",
        "threshold = 40\n",
        "young = df[df['AGE'] < threshold]\n",
        "old = df[df['AGE'] >= threshold]\n",
        "\n",
        "young_pct = young['CLASS'].value_counts(normalize=True) * 100\n",
        "old_pct   = old['CLASS'].value_counts(normalize=True) * 100\n",
        "\n",
        "\n",
        "print(f\"\\nYoung (<{threshold}) distribution (%):\")\n",
        "for cls, val in young_pct.items():\n",
        "    print(f\"  Class {cls}: {val:.2f}%\")\n",
        "\n",
        "print(f\"\\nOlder (≥{threshold}) distribution (%):\")\n",
        "for cls, val in old_pct.items():\n",
        "    print(f\"  Class {cls}: {val:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odniuF-xVhMW",
        "outputId": "be7bbc3b-d4a0-400e-9ab5-e6bfec9d8e6b"
      },
      "execution_count": 295,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Young (<40) distribution (%):\n",
            "  Class P: 44.44%\n",
            "  Class Y: 33.33%\n",
            "  Class N: 22.22%\n",
            "\n",
            "Older (≥40) distribution (%):\n",
            "  Class Y: 84.86%\n",
            "  Class N: 10.19%\n",
            "  Class P: 4.94%\n"
          ]
        }
      ]
    }
  ]
}